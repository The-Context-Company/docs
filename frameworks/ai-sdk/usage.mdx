---
title: "Usage"
description: "Using The Context Company with Vercel AI SDK in 10 lines of code"
---

## Adding custom metadata

Custom metadata allows you to add additional properties to your [agent runs](/concepts#agent-runs).

This is particularly useful for tying agent runs to your own specific business logic, letting you filter and analyze agent runs by user, organization, feature, or some other dimension.

Custom metadata must be passed as a key-value pair to the `metadata` object.

```typescript route.ts
import { openai } from "@ai-sdk/openai";
import { generateText } from "ai";

const { text } = await generateText({
  // ...
  experimental_telemetry: {
    isEnabled: true,
    metadata: {
      // e.g. tag this agent run with a user id
      userId: "4a6b111c-b53a-4d00-a877-67185022ab9e",
    },
  },
});
```

Agent runs are automatically indexed by your custom metadata fields and can be filtered directly in the dashboard.

## Adding user feedback (thumbs up & thumbs down)

User feedback allows you to collect thumbs up and thumbs down reactions from end users on your [agent runs](/concepts#agent-runs).

This is useful for tracking user satisfaction, identifying problematic responses, and filtering agent runs in the dashboard to focus on positive or negative feedback.

#### Step 1: Generate and pass a run ID

```typescript route.ts
import { generateText } from "ai";
import { randomUUID } from "crypto";

// Generate a unique run ID before your agent execution
const runId = randomUUID();

const { text } = await generateText({
  // ...
  experimental_telemetry: {
    isEnabled: true,
    metadata: {
      "tcc.run_id": runId, // Pass the run ID in metadata
    },
  },
});

// Return the runId to your client
return { text, runId };
```

#### Step 2: Submit feedback from your client

Store the `runId` on your client, then when the user provides feedback, submit it using the `submitFeedback` function:

```typescript feedback-route.ts
import { submitFeedback } from "@contextcompany/otel";

// When user clicks thumbs up/down:
await submitFeedback({
  runId: runId, // The run ID from your agent execution
  score: "thumbs_up", // or "thumbs_down"
});
```

Agent runs with feedback can be filtered in the dashboard using the feedback filter.

## Tracking Agent Sessions

[Agent sessions](/concepts#agent-sessions) represents multiple agent runs that are grouped together. The most common use case is tracking entire conversations between a human user and an AI agent in chatbot interfaces.

Agent sessions can be tracked by setting a `tcc.sessionId` key under metadata.

```typescript route.ts
import { generateText } from "ai";

const { text } = await generateText({
  // ...
  experimental_telemetry: {
    isEnabled: true,
    metadata: {
      // use tcc.sessionId to track agent sessions
      "tcc.sessionId": "some-session-id",
    },
  },
});
```

The value of `tcc.sessionId` should be a unique identifier for the agent session. This can be any string, but it's generally recommended to use a UUID.

Agent sessions are automatically indexed and can be filtered directly in the dashboard.


## Debug mode

You can enable debug mode, which will log any spans that are created and exported.

<CodeGroup>

```typescript Next.js
import { registerOTelTCC } from "@contextcompany/otel/nextjs";

export function register() {
  if (process.env.NEXT_RUNTIME === "nodejs") {
    registerOTelTCC({ debug: true });
  }
}
```

```typescript Node.js
import { TCCSpanProcessor } from "@contextcompany/otel";
import { NodeSDK } from "@opentelemetry/sdk-node";

export const tcc = new NodeSDK({
  spanProcessors: [new TCCSpanProcessor({ debug: true })],
});
```

</CodeGroup>

## Examples

See our [examples repository](https://github.com/The-Context-Company/examples) for more detailed usage examples.

Examples currently include:

- [Express (ESM)](https://github.com/The-Context-Company/examples/tree/main/express/esm)
- [Express (CJS)](https://github.com/The-Context-Company/examples/tree/main/express/cjs)